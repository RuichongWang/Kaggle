{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010245,
     "end_time": "2021-01-12T07:24:30.117338",
     "exception": false,
     "start_time": "2021-01-12T07:24:30.107093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T07:24:30.154403Z",
     "iopub.status.busy": "2021-01-12T07:24:30.153757Z",
     "iopub.status.idle": "2021-01-12T07:24:36.739116Z",
     "shell.execute_reply": "2021-01-12T07:24:36.737976Z"
    },
    "papermill": {
     "duration": 6.612613,
     "end_time": "2021-01-12T07:24:36.739240",
     "exception": false,
     "start_time": "2021-01-12T07:24:30.126627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "GROUP_BATCH_SIZE = 4000\n",
    "EPOCHS = 30  # toy data\n",
    "BATCHSIZE = 64\n",
    "LR = 0.0015\n",
    "SPLITS = 6\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "def read_data(kalman):\n",
    "    if kalman:  # if use kalman filtered data\n",
    "        train = pd.read_csv(\n",
    "            '/kaggle/input/ion-switching-kalman-data/train_clean_kalman.csv',\n",
    "            dtype={\n",
    "                'time': np.float32,\n",
    "                'signal': np.float32,\n",
    "                'open_channels': np.int32\n",
    "            })\n",
    "        test = pd.read_csv(\n",
    "            '/kaggle/input/ion-switching-kalman-data/test_clean_kalman.csv',\n",
    "            dtype={\n",
    "                'time': np.float32,\n",
    "                'signal': np.float32\n",
    "            })\n",
    "    else:\n",
    "        train = pd.read_csv('/kaggle/input/data-without-drift/train_clean.csv',\n",
    "                            dtype={\n",
    "                                'time': np.float32,\n",
    "                                'signal': np.float32,\n",
    "                                'open_channels': np.int32\n",
    "                            })\n",
    "        test = pd.read_csv('/kaggle/input/data-without-drift/test_clean.csv',\n",
    "                           dtype={\n",
    "                               'time': np.float32,\n",
    "                               'signal': np.float32\n",
    "                           })\n",
    "\n",
    "    sub = pd.read_csv(\n",
    "        '/kaggle/input/liverpool-ion-switching/sample_submission.csv',\n",
    "        dtype={'time': np.float32})\n",
    "\n",
    "    Y_train_proba = np.load(\n",
    "        \"/kaggle/input/ion-shifted-rfc-proba/Y_train_proba.npy\")\n",
    "    Y_test_proba = np.load(\n",
    "        \"/kaggle/input/ion-shifted-rfc-proba/Y_test_proba.npy\")\n",
    "    for i in range(11):\n",
    "        train[f\"proba_{i}\"] = Y_train_proba[:, i]\n",
    "        test[f\"proba_{i}\"] = Y_test_proba[:, i]\n",
    "    return train, test, sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009476,
     "end_time": "2021-01-12T07:24:36.759359",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.749883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T07:24:36.798923Z",
     "iopub.status.busy": "2021-01-12T07:24:36.797018Z",
     "iopub.status.idle": "2021-01-12T07:24:36.799700Z",
     "shell.execute_reply": "2021-01-12T07:24:36.800202Z"
    },
    "papermill": {
     "duration": 0.031583,
     "end_time": "2021-01-12T07:24:36.800313",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.768730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batching(df, batch_size):  # take every 4000 signals as a sample \n",
    "    df['group'] = df.groupby(df.index // batch_size,\n",
    "                             sort=False)['signal'].agg(['ngroup']).values\n",
    "    df['group'] = df['group'].astype(np.uint16)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize(train, test):\n",
    "    train_input_mean = train.signal.mean()\n",
    "    train_input_sigma = train.signal.std()\n",
    "    train['signal'] = (train.signal - train_input_mean) / train_input_sigma\n",
    "    test['signal'] = (test.signal - train_input_mean) / train_input_sigma\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def lag_with_pct_change(df, windows):    # simple FE\n",
    "    for w in windows:\n",
    "        df['signal_shift_pos_' +\n",
    "           str(w)] = df.groupby('group')['signal'].shift(w).fillna(0)\n",
    "        df['signal_shift_neg_' + str(w)] = df.groupby('group')['signal'].shift(\n",
    "            -1 * w).fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_feat_engineering(df, batch_size):\n",
    "    df = batching(df, batch_size=batch_size)\n",
    "    df = lag_with_pct_change(df, [1, 2, 3])\n",
    "    df['signal_2'] = df['signal']**2\n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_selection(train, test):\n",
    "    features = [\n",
    "        col for col in train.columns\n",
    "        if col not in ['index', 'group', 'open_channels', 'time']\n",
    "    ]\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "    test = test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    for feature in features:\n",
    "        feature_mean = pd.concat([train[feature], test[feature]],\n",
    "                                 axis=0).mean()\n",
    "        train[feature] = train[feature].fillna(feature_mean)\n",
    "        test[feature] = test[feature].fillna(feature_mean)\n",
    "    print('Using the following features')\n",
    "    print(features)\n",
    "    return train, test, features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009704,
     "end_time": "2021-01-12T07:24:36.819740",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.810036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## WaveNet Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T07:24:36.848289Z",
     "iopub.status.busy": "2021-01-12T07:24:36.847627Z",
     "iopub.status.idle": "2021-01-12T07:24:36.850563Z",
     "shell.execute_reply": "2021-01-12T07:24:36.851059Z"
    },
    "papermill": {
     "duration": 0.021843,
     "end_time": "2021-01-12T07:24:36.851176",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.829333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wave_block(x, filters, kernel_size, n): # definition of wavenet\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters=filters, kernel_size=1, padding='same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          padding='same',\n",
    "                          activation='tanh',\n",
    "                          dilation_rate=dilation_rate)(x)\n",
    "        sigm_out = Conv1D(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          dilation_rate=dilation_rate)(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters=filters, kernel_size=1, padding='same')(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009804,
     "end_time": "2021-01-12T07:24:36.870861",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.861057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T07:24:36.907381Z",
     "iopub.status.busy": "2021-01-12T07:24:36.906740Z",
     "iopub.status.idle": "2021-01-12T07:24:36.909741Z",
     "shell.execute_reply": "2021-01-12T07:24:36.910172Z"
    },
    "papermill": {
     "duration": 0.029793,
     "end_time": "2021-01-12T07:24:36.910281",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.880488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Wavenet_LSTM_Classifier(shape_):\n",
    "    inp = Input(shape=(shape_))\n",
    "    x = Conv1D(64,\n",
    "               kernel_size=7,\n",
    "               dilation_rate=1,\n",
    "               strides=1,\n",
    "               padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x *= sigmoid(x)\n",
    "\n",
    "    x1 = wave_block(x, 16, 3, 12)\n",
    "    x2 = Bidirectional(LSTM(16, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.concatenate([x1, x2], axis=2)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x1 = wave_block(x, 32, 3, 8)\n",
    "    x2 = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.concatenate([x1, x2], axis=2)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x1 = wave_block(x, 64, 3, 4)\n",
    "    x2 = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.concatenate([x1, x2], axis=2)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x1 = wave_block(x, 128, 3, 1)\n",
    "    x2 = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.concatenate([x1, x2], axis=2)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(11, activation='softmax', name='out')(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    opt = Adam(lr=LR)\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    tf.keras.utils.plot_model(model,\n",
    "                              to_file=\"Wavenet_LSTM_Classifier.png\",\n",
    "                              show_shapes=False,\n",
    "                              show_layer_names=True,\n",
    "                              rankdir=\"LR\",\n",
    "                              expand_nested=False,\n",
    "                              dpi=96\n",
    "                            )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009743,
     "end_time": "2021-01-12T07:24:36.930097",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.920354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T07:24:36.976288Z",
     "iopub.status.busy": "2021-01-12T07:24:36.960658Z",
     "iopub.status.idle": "2021-01-12T07:24:37.111346Z",
     "shell.execute_reply": "2021-01-12T07:24:37.110713Z"
    },
    "papermill": {
     "duration": 0.169569,
     "end_time": "2021-01-12T07:24:37.111495",
     "exception": false,
     "start_time": "2021-01-12T07:24:36.941926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MacroF1(Callback):\n",
    "    def __init__(self, model, inputs, targets):\n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
    "        score = f1_score(self.targets, pred, average='macro')\n",
    "        print('F1 Macro Score: %s' % score)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 30:\n",
    "        lr = LR\n",
    "    elif epoch < 40:\n",
    "        lr = LR / 3\n",
    "    elif epoch < 50:\n",
    "        lr = LR / 5\n",
    "    elif epoch < 60:\n",
    "        lr = LR / 7\n",
    "    elif epoch < 70:\n",
    "        lr = LR / 9\n",
    "    elif epoch < 80:\n",
    "        lr = LR / 11\n",
    "    elif epoch < 90:\n",
    "        lr = LR / 13\n",
    "    else:\n",
    "        lr = LR / 100\n",
    "    return lr\n",
    "\n",
    "def run_cv_nn(train, test, splits, feats, nn_epochs, nn_batch_size, filename):\n",
    "    seed_everything(SEED)\n",
    "    K.clear_session()\n",
    "    config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                                      inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(),\n",
    "                                config=config)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "    oof_ = np.zeros((len(train), 11))\n",
    "    preds_ = np.zeros((len(test), 11))\n",
    "    target = ['open_channels']\n",
    "    group = train['group']\n",
    "\n",
    "    kf = GroupKFold(n_splits=splits)\n",
    "    splits = [x for x in kf.split(train, train[target], group)]\n",
    "    splits = list(\n",
    "        map(lambda x: [np.unique(group[x[0]]),\n",
    "                       np.unique(group[x[1]]), x[1]], splits))\n",
    "    tr = pd.concat([pd.get_dummies(train.open_channels), train[['group']]],\n",
    "                   axis=1)\n",
    "\n",
    "    tr.columns = ['target_' + str(i) for i in range(11)] + ['group']\n",
    "    target_cols = ['target_' + str(i) for i in range(11)]\n",
    "    train_tr = np.array(\n",
    "        list(tr.groupby('group').apply(\n",
    "            lambda x: x[target_cols].values))).astype(np.float32)\n",
    "\n",
    "    train = np.array(\n",
    "        list(train.groupby('group').apply(lambda x: x[feats].values)))\n",
    "    test = np.array(\n",
    "        list(test.groupby('group').apply(lambda x: x[feats].values)))\n",
    "\n",
    "    for n_fold, (tr_idx, val_idx, val_orig_idx) in enumerate(splits[0:],\n",
    "                                                             start=0):\n",
    "        train_x, train_y = train[tr_idx], train_tr[tr_idx]\n",
    "        valid_x, valid_y = train[val_idx], train_tr[val_idx]\n",
    "\n",
    "        gc.collect()\n",
    "        shape_ = (None, train_x.shape[2])\n",
    "        model = Wavenet_LSTM_Classifier(shape_)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath='/kaggle/output/%s.h5' %\n",
    "                                     filename,\n",
    "                                     monitor=MacroF1(model, valid_x, valid_y),\n",
    "                                     mode='max',\n",
    "                                     save_best_only='True')\n",
    "        cb_lr_schedule = LearningRateScheduler(lr_schedule)\n",
    "        model.fit(train_x,\n",
    "                  train_y,\n",
    "                  epochs=nn_epochs,\n",
    "                  callbacks=[\n",
    "                      cb_lr_schedule,\n",
    "                      MacroF1(model, valid_x, valid_y), checkpoint\n",
    "                  ],\n",
    "                  batch_size=nn_batch_size,\n",
    "                  verbose=1,\n",
    "                  validation_data=(valid_x, valid_y))\n",
    "\n",
    "        preds_f = model.predict(valid_x)\n",
    "        f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),\n",
    "                             np.argmax(preds_f, axis=2).reshape(-1),\n",
    "                             average='macro')\n",
    "        model.save(\"/kaggle/working/%s_%s.h5\" % (filename, f1_score_))\n",
    "        print('Training fold %s completed. macro f1 score : %s' %\n",
    "              (n_fold + 1,f1_score_))\n",
    "\n",
    "        preds_f = preds_f.reshape(-1, preds_f.shape[-1])\n",
    "        oof_[val_orig_idx, :] += preds_f\n",
    "\n",
    "        te_preds = model.predict(test)\n",
    "        te_preds = te_preds.reshape(-1, te_preds.shape[-1])\n",
    "        preds_ += te_preds / SPLITS\n",
    "\n",
    "    f1_score_ = f1_score(np.argmax(train_tr, axis=2).reshape(-1),\n",
    "                         np.argmax(oof_, axis=1).reshape(-1),\n",
    "                         average='macro')\n",
    "    print('Training completed. oof macro f1 score : %s' % f1_score_)\n",
    "    np.save('/kaggle/working/%s_predicted_test.npy' % (round(f1_score_, 6)), preds_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010086,
     "end_time": "2021-01-12T07:24:37.132410",
     "exception": false,
     "start_time": "2021-01-12T07:24:37.122324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Applying all steps to kalman and non_kalman data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T07:24:37.172710Z",
     "iopub.status.busy": "2021-01-12T07:24:37.172109Z",
     "iopub.status.idle": "2021-01-12T11:15:19.011844Z",
     "shell.execute_reply": "2021-01-12T11:15:19.011260Z"
    },
    "papermill": {
     "duration": 13841.869253,
     "end_time": "2021-01-12T11:15:19.011972",
     "exception": false,
     "start_time": "2021-01-12T07:24:37.142719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following features\n",
      "['signal', 'proba_0', 'proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9', 'proba_10', 'signal_shift_pos_1', 'signal_shift_neg_1', 'signal_shift_pos_2', 'signal_shift_neg_2', 'signal_shift_pos_3', 'signal_shift_neg_3', 'signal_2']\n",
      "Train on 1041 samples, validate on 209 samples\n",
      "Epoch 1/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.8851 - accuracy: 0.7094F1 Macro Score: 0.3893027283186268\n",
      "1041/1041 [==============================] - 70s 67ms/sample - loss: 0.8782 - accuracy: 0.7116 - val_loss: 1.3042 - val_accuracy: 0.6180\n",
      "Epoch 2/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.8641F1 Macro Score: 0.5116518126075764\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.3636 - accuracy: 0.8649 - val_loss: 1.1846 - val_accuracy: 0.7465\n",
      "Epoch 3/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9244F1 Macro Score: 0.6464006687013452\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.2178 - accuracy: 0.9251 - val_loss: 1.0406 - val_accuracy: 0.8487\n",
      "Epoch 4/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9496F1 Macro Score: 0.6796082195334566\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1569 - accuracy: 0.9498 - val_loss: 0.9000 - val_accuracy: 0.8763\n",
      "Epoch 5/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9591F1 Macro Score: 0.7050049135525506\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1300 - accuracy: 0.9591 - val_loss: 0.7664 - val_accuracy: 0.8949\n",
      "Epoch 6/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9618F1 Macro Score: 0.7014635608603372\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1220 - accuracy: 0.9618 - val_loss: 0.6149 - val_accuracy: 0.8900\n",
      "Epoch 7/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9635F1 Macro Score: 0.747697238808286\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1142 - accuracy: 0.9638 - val_loss: 0.4783 - val_accuracy: 0.9162\n",
      "Epoch 8/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9650F1 Macro Score: 0.7724690857899597\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1102 - accuracy: 0.9648 - val_loss: 0.3936 - val_accuracy: 0.9242\n",
      "Epoch 9/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 0.9655F1 Macro Score: 0.7906444820326438\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.1070 - accuracy: 0.9654 - val_loss: 0.3275 - val_accuracy: 0.9324\n",
      "Epoch 10/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.9650F1 Macro Score: 0.8068570342421684\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1071 - accuracy: 0.9651 - val_loss: 0.2712 - val_accuracy: 0.9386\n",
      "Epoch 11/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9661F1 Macro Score: 0.8700226093645004\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.1040 - accuracy: 0.9660 - val_loss: 0.2086 - val_accuracy: 0.9505\n",
      "Epoch 12/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9661F1 Macro Score: 0.8751355092739945\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1025 - accuracy: 0.9661 - val_loss: 0.1857 - val_accuracy: 0.9510\n",
      "Epoch 13/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9667F1 Macro Score: 0.8907896202168128\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1001 - accuracy: 0.9665 - val_loss: 0.1627 - val_accuracy: 0.9558\n",
      "Epoch 14/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9666F1 Macro Score: 0.907586834201105\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0996 - accuracy: 0.9665 - val_loss: 0.1418 - val_accuracy: 0.9591\n",
      "Epoch 15/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9666F1 Macro Score: 0.8948183806500246\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0989 - accuracy: 0.9667 - val_loss: 0.1400 - val_accuracy: 0.9563\n",
      "Epoch 16/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9665F1 Macro Score: 0.8846647343803475\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0987 - accuracy: 0.9666 - val_loss: 0.1401 - val_accuracy: 0.9537\n",
      "Epoch 17/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9668F1 Macro Score: 0.9227989478758795\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0975 - accuracy: 0.9669 - val_loss: 0.1132 - val_accuracy: 0.9633\n",
      "Epoch 18/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.9668F1 Macro Score: 0.9235801787472435\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0965 - accuracy: 0.9669 - val_loss: 0.1091 - val_accuracy: 0.9637\n",
      "Epoch 19/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9671F1 Macro Score: 0.9265465528668599\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0958 - accuracy: 0.9670 - val_loss: 0.1076 - val_accuracy: 0.9638\n",
      "Epoch 20/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9669F1 Macro Score: 0.9345402316479204\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.1001 - val_accuracy: 0.9659\n",
      "Epoch 21/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9666F1 Macro Score: 0.9357902093774662\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0982 - accuracy: 0.9666 - val_loss: 0.0965 - val_accuracy: 0.9663\n",
      "Epoch 22/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9670F1 Macro Score: 0.9345500182553369\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0974 - accuracy: 0.9666 - val_loss: 0.1001 - val_accuracy: 0.9657\n",
      "Epoch 23/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9664F1 Macro Score: 0.9313765566905073\n",
      "1041/1041 [==============================] - 38s 36ms/sample - loss: 0.0971 - accuracy: 0.9667 - val_loss: 0.0999 - val_accuracy: 0.9654\n",
      "Epoch 24/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9673F1 Macro Score: 0.9351947534846509\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0943 - accuracy: 0.9673 - val_loss: 0.0961 - val_accuracy: 0.9662\n",
      "Epoch 25/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9674F1 Macro Score: 0.9357305662953066\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0933 - accuracy: 0.9675 - val_loss: 0.0943 - val_accuracy: 0.9665\n",
      "Epoch 26/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9672F1 Macro Score: 0.9363774208146945\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0926 - accuracy: 0.9675 - val_loss: 0.0936 - val_accuracy: 0.9666\n",
      "Epoch 27/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9674F1 Macro Score: 0.9353588561222698\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0938 - accuracy: 0.9673 - val_loss: 0.0957 - val_accuracy: 0.9661\n",
      "Epoch 28/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9670F1 Macro Score: 0.9333269790955455\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0937 - accuracy: 0.9672 - val_loss: 0.0962 - val_accuracy: 0.9658\n",
      "Epoch 29/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9678F1 Macro Score: 0.9366132144352616\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0921 - accuracy: 0.9675 - val_loss: 0.0918 - val_accuracy: 0.9669\n",
      "Epoch 30/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9676F1 Macro Score: 0.9359520681051464\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0916 - accuracy: 0.9675 - val_loss: 0.0928 - val_accuracy: 0.9666\n",
      "Training fold 1 completed. macro f1 score : 0.9359520681051464\n",
      "Train on 1041 samples, validate on 209 samples\n",
      "Epoch 1/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.8375 - accuracy: 0.7045F1 Macro Score: 0.3588641567448207\n",
      "1041/1041 [==============================] - 62s 59ms/sample - loss: 0.8332 - accuracy: 0.7063 - val_loss: 1.2369 - val_accuracy: 0.6516\n",
      "Epoch 2/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8547F1 Macro Score: 0.49324199964909565\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.3822 - accuracy: 0.8558 - val_loss: 1.0913 - val_accuracy: 0.7370\n",
      "Epoch 3/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9303F1 Macro Score: 0.5206427734333468\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.2035 - accuracy: 0.9310 - val_loss: 0.9925 - val_accuracy: 0.7976\n",
      "Epoch 4/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9539F1 Macro Score: 0.5550963379168677\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1450 - accuracy: 0.9541 - val_loss: 0.7928 - val_accuracy: 0.8167\n",
      "Epoch 5/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1275 - accuracy: 0.9600F1 Macro Score: 0.5498203637332121\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1274 - accuracy: 0.9601 - val_loss: 0.6953 - val_accuracy: 0.8304\n",
      "Epoch 6/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 0.9615F1 Macro Score: 0.6736278381197729\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1230 - accuracy: 0.9615 - val_loss: 0.5586 - val_accuracy: 0.8772\n",
      "Epoch 7/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9629F1 Macro Score: 0.6462304828981558\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1158 - accuracy: 0.9632 - val_loss: 0.4819 - val_accuracy: 0.8670\n",
      "Epoch 8/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9646F1 Macro Score: 0.6810846216171189\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1107 - accuracy: 0.9643 - val_loss: 0.4017 - val_accuracy: 0.8754\n",
      "Epoch 9/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9651F1 Macro Score: 0.7187462436053093\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1072 - accuracy: 0.9650 - val_loss: 0.3477 - val_accuracy: 0.8890\n",
      "Epoch 10/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9645F1 Macro Score: 0.7935204688065304\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1077 - accuracy: 0.9647 - val_loss: 0.2832 - val_accuracy: 0.9164\n",
      "Epoch 11/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1044 - accuracy: 0.9655F1 Macro Score: 0.8699730090553014\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.1046 - accuracy: 0.9654 - val_loss: 0.2327 - val_accuracy: 0.9385\n",
      "Epoch 12/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9654F1 Macro Score: 0.8935091630236607\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1042 - accuracy: 0.9653 - val_loss: 0.1949 - val_accuracy: 0.9516\n",
      "Epoch 13/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9660F1 Macro Score: 0.9108810441485741\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1021 - accuracy: 0.9658 - val_loss: 0.1633 - val_accuracy: 0.9582\n",
      "Epoch 14/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.9662F1 Macro Score: 0.9065451730540733\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.1002 - accuracy: 0.9661 - val_loss: 0.1516 - val_accuracy: 0.9572\n",
      "Epoch 15/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9661F1 Macro Score: 0.9207966515124145\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0995 - accuracy: 0.9662 - val_loss: 0.1330 - val_accuracy: 0.9613\n",
      "Epoch 16/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9662F1 Macro Score: 0.9194619545004961\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0982 - accuracy: 0.9664 - val_loss: 0.1319 - val_accuracy: 0.9596\n",
      "Epoch 17/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9661F1 Macro Score: 0.9176143975402407\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0987 - accuracy: 0.9662 - val_loss: 0.1181 - val_accuracy: 0.9616\n",
      "Epoch 18/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 0.9660F1 Macro Score: 0.933750996734661\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.0987 - accuracy: 0.9661 - val_loss: 0.1027 - val_accuracy: 0.9669\n",
      "Epoch 19/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9667F1 Macro Score: 0.9335158397700368\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0964 - accuracy: 0.9666 - val_loss: 0.1024 - val_accuracy: 0.9663\n",
      "Epoch 20/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9663F1 Macro Score: 0.9355914369482092\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0969 - accuracy: 0.9664 - val_loss: 0.0980 - val_accuracy: 0.9672\n",
      "Epoch 21/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9667F1 Macro Score: 0.9376385768857737\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0966 - accuracy: 0.9666 - val_loss: 0.0918 - val_accuracy: 0.9683\n",
      "Epoch 22/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9670F1 Macro Score: 0.9367103778718522\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0957 - accuracy: 0.9666 - val_loss: 0.0932 - val_accuracy: 0.9677\n",
      "Epoch 23/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9665F1 Macro Score: 0.9368114064635542\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0947 - accuracy: 0.9668 - val_loss: 0.0918 - val_accuracy: 0.9680\n",
      "Epoch 24/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9670F1 Macro Score: 0.9358071531279072\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0942 - accuracy: 0.9670 - val_loss: 0.0923 - val_accuracy: 0.9678\n",
      "Epoch 25/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9670F1 Macro Score: 0.9379395953801304\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0932 - accuracy: 0.9671 - val_loss: 0.0881 - val_accuracy: 0.9685\n",
      "Epoch 26/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9668F1 Macro Score: 0.9363760351853024\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0930 - accuracy: 0.9671 - val_loss: 0.0911 - val_accuracy: 0.9679\n",
      "Epoch 27/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9672F1 Macro Score: 0.9378834490794088\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0932 - accuracy: 0.9670 - val_loss: 0.0875 - val_accuracy: 0.9685\n",
      "Epoch 28/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9670F1 Macro Score: 0.9363509310036132\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0921 - accuracy: 0.9672 - val_loss: 0.0902 - val_accuracy: 0.9680\n",
      "Epoch 29/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9673F1 Macro Score: 0.9363833434547048\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0927 - accuracy: 0.9669 - val_loss: 0.0897 - val_accuracy: 0.9681\n",
      "Epoch 30/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9670F1 Macro Score: 0.936774143177665\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0925 - accuracy: 0.9669 - val_loss: 0.0881 - val_accuracy: 0.9683\n",
      "Training fold 2 completed. macro f1 score : 0.936774143177665\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.9511 - accuracy: 0.6970F1 Macro Score: 0.3127604781707195\n",
      "1042/1042 [==============================] - 63s 61ms/sample - loss: 0.9449 - accuracy: 0.6983 - val_loss: 1.3756 - val_accuracy: 0.5168\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3705 - accuracy: 0.8598F1 Macro Score: 0.3647898405097582\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3690 - accuracy: 0.8605 - val_loss: 1.1170 - val_accuracy: 0.5688\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9309F1 Macro Score: 0.4831652832691228\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.2016 - accuracy: 0.9313 - val_loss: 0.9479 - val_accuracy: 0.7001\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1509 - accuracy: 0.9530F1 Macro Score: 0.5775237500338003\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1502 - accuracy: 0.9533 - val_loss: 0.8248 - val_accuracy: 0.8000\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9609F1 Macro Score: 0.7119393336526207\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1292 - accuracy: 0.9607 - val_loss: 0.6854 - val_accuracy: 0.8694\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9626F1 Macro Score: 0.7252172189081733\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1208 - accuracy: 0.9628 - val_loss: 0.6178 - val_accuracy: 0.8427\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9641F1 Macro Score: 0.7799151757625045\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1176 - accuracy: 0.9634 - val_loss: 0.4929 - val_accuracy: 0.8890\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9646F1 Macro Score: 0.7707237070299225\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1255 - accuracy: 0.9608 - val_loss: 0.4823 - val_accuracy: 0.8786\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9545F1 Macro Score: 0.8641933192063433\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1503 - accuracy: 0.9546 - val_loss: 0.3915 - val_accuracy: 0.9343\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9628F1 Macro Score: 0.9034193927861884\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1226 - accuracy: 0.9631 - val_loss: 0.2915 - val_accuracy: 0.9546\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9651F1 Macro Score: 0.9188262890244883\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1111 - accuracy: 0.9652 - val_loss: 0.2214 - val_accuracy: 0.9601\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 0.9654F1 Macro Score: 0.9193742051652084\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1077 - accuracy: 0.9656 - val_loss: 0.2020 - val_accuracy: 0.9615\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9660F1 Macro Score: 0.9313243888423706\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1047 - accuracy: 0.9661 - val_loss: 0.1572 - val_accuracy: 0.9652\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9658F1 Macro Score: 0.931174441560455\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1052 - accuracy: 0.9659 - val_loss: 0.1517 - val_accuracy: 0.9652\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9660F1 Macro Score: 0.9328237648796769\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1036 - accuracy: 0.9661 - val_loss: 0.1242 - val_accuracy: 0.9662\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9667F1 Macro Score: 0.9320822457063805\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1006 - accuracy: 0.9666 - val_loss: 0.1192 - val_accuracy: 0.9656\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9667F1 Macro Score: 0.9320022003242425\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0995 - accuracy: 0.9668 - val_loss: 0.1189 - val_accuracy: 0.9652\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 0.9668F1 Macro Score: 0.9324182903620213\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0995 - accuracy: 0.9666 - val_loss: 0.1126 - val_accuracy: 0.9655\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9668F1 Macro Score: 0.9335117370319007\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.1058 - val_accuracy: 0.9660\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9665F1 Macro Score: 0.9349875925168067\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0980 - accuracy: 0.9668 - val_loss: 0.1014 - val_accuracy: 0.9668\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9673F1 Macro Score: 0.9300763953796565\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0964 - accuracy: 0.9671 - val_loss: 0.1081 - val_accuracy: 0.9646\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9668F1 Macro Score: 0.934241649016267\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0976 - accuracy: 0.9668 - val_loss: 0.1013 - val_accuracy: 0.9664\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9672F1 Macro Score: 0.9370409514808583\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0959 - accuracy: 0.9671 - val_loss: 0.0934 - val_accuracy: 0.9678\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9669F1 Macro Score: 0.9368924762954475\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0950 - accuracy: 0.9672 - val_loss: 0.0926 - val_accuracy: 0.9678\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9672F1 Macro Score: 0.9374757472550038\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0947 - accuracy: 0.9672 - val_loss: 0.0914 - val_accuracy: 0.9679\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 0.9669F1 Macro Score: 0.9290641572345877\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0976 - accuracy: 0.9662 - val_loss: 0.1196 - val_accuracy: 0.9627\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9630F1 Macro Score: 0.928729731862565\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1165 - accuracy: 0.9627 - val_loss: 0.1134 - val_accuracy: 0.9648\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9661F1 Macro Score: 0.9311271509327571\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1054 - accuracy: 0.9658 - val_loss: 0.1073 - val_accuracy: 0.9655\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9658F1 Macro Score: 0.934116713205795\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1044 - accuracy: 0.9656 - val_loss: 0.0964 - val_accuracy: 0.9674\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9669F1 Macro Score: 0.935740080640285\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0987 - accuracy: 0.9669 - val_loss: 0.0973 - val_accuracy: 0.9672\n",
      "Training fold 3 completed. macro f1 score : 0.935740080640285\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.8905 - accuracy: 0.7043F1 Macro Score: 0.39511020026028415\n",
      "1042/1042 [==============================] - 62s 60ms/sample - loss: 0.8844 - accuracy: 0.7058 - val_loss: 1.3747 - val_accuracy: 0.6534\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3242 - accuracy: 0.8787F1 Macro Score: 0.4997509643717502\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.3226 - accuracy: 0.8795 - val_loss: 1.1997 - val_accuracy: 0.7465\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1844 - accuracy: 0.9391F1 Macro Score: 0.4785583160275239\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1835 - accuracy: 0.9394 - val_loss: 1.1198 - val_accuracy: 0.7417\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9550F1 Macro Score: 0.5575328555706479\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1447 - accuracy: 0.9553 - val_loss: 1.0511 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9618F1 Macro Score: 0.6196310512498587\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1253 - accuracy: 0.9616 - val_loss: 0.8022 - val_accuracy: 0.8406\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9633F1 Macro Score: 0.7125946518376672\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1177 - accuracy: 0.9635 - val_loss: 0.6824 - val_accuracy: 0.8867\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9644F1 Macro Score: 0.7524926971609687\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1150 - accuracy: 0.9639 - val_loss: 0.5542 - val_accuracy: 0.9064\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9656F1 Macro Score: 0.7459765425703314\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1185 - accuracy: 0.9626 - val_loss: 0.5374 - val_accuracy: 0.9019\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9587F1 Macro Score: 0.7770751441772812\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1372 - accuracy: 0.9588 - val_loss: 0.4757 - val_accuracy: 0.8985\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9641F1 Macro Score: 0.8413400798616749\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1156 - accuracy: 0.9644 - val_loss: 0.3258 - val_accuracy: 0.9207\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9656F1 Macro Score: 0.896059665131179\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1070 - accuracy: 0.9658 - val_loss: 0.2346 - val_accuracy: 0.9494\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.9659F1 Macro Score: 0.9052884496884119\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1053 - accuracy: 0.9660 - val_loss: 0.2049 - val_accuracy: 0.9535\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.9662F1 Macro Score: 0.9204050378761565\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1024 - accuracy: 0.9664 - val_loss: 0.1601 - val_accuracy: 0.9604\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.9666F1 Macro Score: 0.9136494101228174\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1013 - accuracy: 0.9666 - val_loss: 0.1504 - val_accuracy: 0.9586\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9665F1 Macro Score: 0.9248209352913601\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.1278 - val_accuracy: 0.9621\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9669F1 Macro Score: 0.9215068816150566\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0982 - accuracy: 0.9669 - val_loss: 0.1214 - val_accuracy: 0.9632\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9671F1 Macro Score: 0.9314493710852653\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0967 - accuracy: 0.9671 - val_loss: 0.1145 - val_accuracy: 0.9644\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9673F1 Macro Score: 0.9294140966664698\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0962 - accuracy: 0.9671 - val_loss: 0.1240 - val_accuracy: 0.9632\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9672F1 Macro Score: 0.9272265451282894\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0959 - accuracy: 0.9671 - val_loss: 0.1142 - val_accuracy: 0.9625\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9668F1 Macro Score: 0.9299827275387631\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0958 - accuracy: 0.9671 - val_loss: 0.1091 - val_accuracy: 0.9637\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9676F1 Macro Score: 0.9337428861435225\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0943 - accuracy: 0.9673 - val_loss: 0.1002 - val_accuracy: 0.9657\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9672F1 Macro Score: 0.9348706300507541\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0942 - accuracy: 0.9672 - val_loss: 0.0999 - val_accuracy: 0.9659\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9674F1 Macro Score: 0.9360738561073714\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0939 - accuracy: 0.9673 - val_loss: 0.0945 - val_accuracy: 0.9666\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9673F1 Macro Score: 0.9364866499679224\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0923 - accuracy: 0.9676 - val_loss: 0.0930 - val_accuracy: 0.9668\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9675F1 Macro Score: 0.9358734199528875\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0922 - accuracy: 0.9675 - val_loss: 0.0945 - val_accuracy: 0.9665\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9670F1 Macro Score: 0.9336059840418323\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0937 - accuracy: 0.9670 - val_loss: 0.1022 - val_accuracy: 0.9653\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9666F1 Macro Score: 0.9308716525830282\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1002 - accuracy: 0.9664 - val_loss: 0.1047 - val_accuracy: 0.9653\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9664F1 Macro Score: 0.9344422279963481\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0994 - accuracy: 0.9661 - val_loss: 0.0979 - val_accuracy: 0.9661\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9661F1 Macro Score: 0.9272851865352905\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1000 - accuracy: 0.9658 - val_loss: 0.1001 - val_accuracy: 0.9658\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9668F1 Macro Score: 0.9364211867558395\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0962 - accuracy: 0.9669 - val_loss: 0.0925 - val_accuracy: 0.9671\n",
      "Training fold 4 completed. macro f1 score : 0.9364211867558395\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.8592 - accuracy: 0.7106F1 Macro Score: 0.42832523292968183\n",
      "1042/1042 [==============================] - 60s 58ms/sample - loss: 0.8525 - accuracy: 0.7123 - val_loss: 1.2352 - val_accuracy: 0.6306\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.8864F1 Macro Score: 0.5363885013283747\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3019 - accuracy: 0.8870 - val_loss: 1.0927 - val_accuracy: 0.7631\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9465F1 Macro Score: 0.6096089303600555\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1638 - accuracy: 0.9468 - val_loss: 0.9115 - val_accuracy: 0.8273\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9574F1 Macro Score: 0.6713023896510285\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1354 - accuracy: 0.9576 - val_loss: 0.7793 - val_accuracy: 0.8638\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9616F1 Macro Score: 0.6669778841945494\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1220 - accuracy: 0.9614 - val_loss: 0.6648 - val_accuracy: 0.8626\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 0.9623F1 Macro Score: 0.7107812717458918\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1181 - accuracy: 0.9624 - val_loss: 0.5571 - val_accuracy: 0.8918\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9638F1 Macro Score: 0.7583567484321659\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1167 - accuracy: 0.9629 - val_loss: 0.4409 - val_accuracy: 0.9123\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9642F1 Macro Score: 0.6672619074669421\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1222 - accuracy: 0.9606 - val_loss: 0.5510 - val_accuracy: 0.8616\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9546F1 Macro Score: 0.7844349012237892\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1472 - accuracy: 0.9546 - val_loss: 0.3190 - val_accuracy: 0.9200\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9631F1 Macro Score: 0.8516842552413574\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1184 - accuracy: 0.9634 - val_loss: 0.2157 - val_accuracy: 0.9507\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9646F1 Macro Score: 0.8983213380038709\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1093 - accuracy: 0.9647 - val_loss: 0.1773 - val_accuracy: 0.9555\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9655F1 Macro Score: 0.9106455059604385\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1045 - accuracy: 0.9657 - val_loss: 0.1539 - val_accuracy: 0.9599\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9659F1 Macro Score: 0.9122277889506573\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1015 - accuracy: 0.9660 - val_loss: 0.1470 - val_accuracy: 0.9581\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9660F1 Macro Score: 0.9218449167411801\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1022 - accuracy: 0.9661 - val_loss: 0.1300 - val_accuracy: 0.9631\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9661F1 Macro Score: 0.92773260974177\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1005 - accuracy: 0.9662 - val_loss: 0.1232 - val_accuracy: 0.9638\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9666F1 Macro Score: 0.9286751875830859\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0982 - accuracy: 0.9666 - val_loss: 0.1119 - val_accuracy: 0.9653\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9666F1 Macro Score: 0.9334017946708687\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0976 - accuracy: 0.9666 - val_loss: 0.1083 - val_accuracy: 0.9658\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9665F1 Macro Score: 0.933699888067025\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0982 - accuracy: 0.9664 - val_loss: 0.1037 - val_accuracy: 0.9663\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9668F1 Macro Score: 0.9351742327918793\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0962 - accuracy: 0.9668 - val_loss: 0.1013 - val_accuracy: 0.9663\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9666F1 Macro Score: 0.9351176819993031\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0958 - accuracy: 0.9668 - val_loss: 0.1018 - val_accuracy: 0.9661\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9671F1 Macro Score: 0.936885828341666\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0948 - accuracy: 0.9670 - val_loss: 0.0937 - val_accuracy: 0.9676\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9670F1 Macro Score: 0.9368192870372625\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0948 - accuracy: 0.9669 - val_loss: 0.0943 - val_accuracy: 0.9672\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9671F1 Macro Score: 0.9379492158841644\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0944 - accuracy: 0.9670 - val_loss: 0.0899 - val_accuracy: 0.9680\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9669F1 Macro Score: 0.9380553827430114\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0933 - accuracy: 0.9671 - val_loss: 0.0888 - val_accuracy: 0.9681\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9671F1 Macro Score: 0.9370269931816143\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.0903 - val_accuracy: 0.9678\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9665F1 Macro Score: 0.9372492792293787\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0958 - accuracy: 0.9666 - val_loss: 0.0947 - val_accuracy: 0.9674\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9661F1 Macro Score: 0.9292356082434791\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1026 - accuracy: 0.9659 - val_loss: 0.1041 - val_accuracy: 0.9647\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9670F1 Macro Score: 0.9383850595938796\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0971 - accuracy: 0.9667 - val_loss: 0.0898 - val_accuracy: 0.9680\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9661F1 Macro Score: 0.9368398181720486\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0986 - accuracy: 0.9658 - val_loss: 0.0933 - val_accuracy: 0.9673\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9669F1 Macro Score: 0.9385155906292653\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0955 - accuracy: 0.9669 - val_loss: 0.0892 - val_accuracy: 0.9682\n",
      "Training fold 5 completed. macro f1 score : 0.9385155906292653\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.8326 - accuracy: 0.7061F1 Macro Score: 0.3425804680109405\n",
      "1042/1042 [==============================] - 60s 58ms/sample - loss: 0.8279 - accuracy: 0.7074 - val_loss: 1.3477 - val_accuracy: 0.5225\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3327 - accuracy: 0.8727F1 Macro Score: 0.51903285697823\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3311 - accuracy: 0.8734 - val_loss: 1.2123 - val_accuracy: 0.7406\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9380F1 Macro Score: 0.5977209377046525\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1827 - accuracy: 0.9384 - val_loss: 1.0936 - val_accuracy: 0.8156\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1418 - accuracy: 0.9555F1 Macro Score: 0.6522325793096534\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1411 - accuracy: 0.9558 - val_loss: 0.9979 - val_accuracy: 0.8397\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9618F1 Macro Score: 0.6502906425109809\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1218 - accuracy: 0.9617 - val_loss: 0.8682 - val_accuracy: 0.8226\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9629F1 Macro Score: 0.6914640676902972\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1162 - accuracy: 0.9631 - val_loss: 0.7744 - val_accuracy: 0.8544\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9641F1 Macro Score: 0.7409945863892439\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1155 - accuracy: 0.9633 - val_loss: 0.6130 - val_accuracy: 0.8943\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9647F1 Macro Score: 0.7353741849980765\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1191 - accuracy: 0.9616 - val_loss: 0.6106 - val_accuracy: 0.8214\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9574F1 Macro Score: 0.7022513019652186\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1376 - accuracy: 0.9575 - val_loss: 0.5673 - val_accuracy: 0.8423\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9639F1 Macro Score: 0.7787207220995107\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1142 - accuracy: 0.9642 - val_loss: 0.4695 - val_accuracy: 0.8169\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9655F1 Macro Score: 0.8536048209780219\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1063 - accuracy: 0.9656 - val_loss: 0.3085 - val_accuracy: 0.9227\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.9658F1 Macro Score: 0.8829630781357921\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1037 - accuracy: 0.9659 - val_loss: 0.2585 - val_accuracy: 0.9406\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9663F1 Macro Score: 0.9113049057275578\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1007 - accuracy: 0.9664 - val_loss: 0.1769 - val_accuracy: 0.9560\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9661F1 Macro Score: 0.9081766744309526\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1015 - accuracy: 0.9662 - val_loss: 0.1588 - val_accuracy: 0.9579\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9662F1 Macro Score: 0.9277201575915744\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1003 - accuracy: 0.9663 - val_loss: 0.1299 - val_accuracy: 0.9626\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9668F1 Macro Score: 0.9220127440002169\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0978 - accuracy: 0.9668 - val_loss: 0.1234 - val_accuracy: 0.9626\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9668F1 Macro Score: 0.9313626382922616\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0965 - accuracy: 0.9668 - val_loss: 0.1151 - val_accuracy: 0.9646\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9670F1 Macro Score: 0.9319578424235929\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0960 - accuracy: 0.9668 - val_loss: 0.1112 - val_accuracy: 0.9652\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9670F1 Macro Score: 0.9299450330282515\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.1107 - val_accuracy: 0.9641\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9667F1 Macro Score: 0.9325583534483998\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0952 - accuracy: 0.9669 - val_loss: 0.1039 - val_accuracy: 0.9653\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9672F1 Macro Score: 0.9356980311842104\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0939 - accuracy: 0.9671 - val_loss: 0.0970 - val_accuracy: 0.9670\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9673F1 Macro Score: 0.9379083887467872\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0931 - accuracy: 0.9672 - val_loss: 0.0904 - val_accuracy: 0.9682\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9670F1 Macro Score: 0.9378710468383347\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0949 - accuracy: 0.9669 - val_loss: 0.0901 - val_accuracy: 0.9681\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9670F1 Macro Score: 0.9360741870099385\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0927 - accuracy: 0.9672 - val_loss: 0.0900 - val_accuracy: 0.9678\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9671F1 Macro Score: 0.9350462734625843\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0928 - accuracy: 0.9672 - val_loss: 0.0963 - val_accuracy: 0.9665\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9666F1 Macro Score: 0.9291226392390723\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0947 - accuracy: 0.9668 - val_loss: 0.1054 - val_accuracy: 0.9642\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9669F1 Macro Score: 0.9334196493771372\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0972 - accuracy: 0.9666 - val_loss: 0.0969 - val_accuracy: 0.9665\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9673F1 Macro Score: 0.936851850228516\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0941 - accuracy: 0.9671 - val_loss: 0.0903 - val_accuracy: 0.9678\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9674F1 Macro Score: 0.9384703579856097\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0929 - accuracy: 0.9672 - val_loss: 0.0884 - val_accuracy: 0.9683\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 0.9674F1 Macro Score: 0.9376809156696791\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0917 - accuracy: 0.9674 - val_loss: 0.0891 - val_accuracy: 0.9681\n",
      "Training fold 6 completed. macro f1 score : 0.9376809156696791\n",
      "Training completed. oof macro f1 score : 0.9368702128724201\n",
      "Using the following features\n",
      "['signal', 'proba_0', 'proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9', 'proba_10', 'signal_shift_pos_1', 'signal_shift_neg_1', 'signal_shift_pos_2', 'signal_shift_neg_2', 'signal_shift_pos_3', 'signal_shift_neg_3', 'signal_2']\n",
      "Train on 1041 samples, validate on 209 samples\n",
      "Epoch 1/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.8846 - accuracy: 0.7089F1 Macro Score: 0.3832247053740726\n",
      "1041/1041 [==============================] - 60s 57ms/sample - loss: 0.8783 - accuracy: 0.7108 - val_loss: 1.2669 - val_accuracy: 0.6164\n",
      "Epoch 2/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.3727 - accuracy: 0.8621F1 Macro Score: 0.4025050352035636\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.3710 - accuracy: 0.8629 - val_loss: 1.2018 - val_accuracy: 0.6606\n",
      "Epoch 3/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9248F1 Macro Score: 0.607119850212342\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.2176 - accuracy: 0.9255 - val_loss: 1.0846 - val_accuracy: 0.8267\n",
      "Epoch 4/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9501F1 Macro Score: 0.5946940173944802\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1549 - accuracy: 0.9503 - val_loss: 0.9357 - val_accuracy: 0.8296\n",
      "Epoch 5/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9591F1 Macro Score: 0.6535691259326367\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1305 - accuracy: 0.9589 - val_loss: 0.7800 - val_accuracy: 0.8672\n",
      "Epoch 6/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9583F1 Macro Score: 0.607729067992383\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1325 - accuracy: 0.9584 - val_loss: 0.6708 - val_accuracy: 0.8576\n",
      "Epoch 7/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9629F1 Macro Score: 0.6886599121538035\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1180 - accuracy: 0.9631 - val_loss: 0.5097 - val_accuracy: 0.8947\n",
      "Epoch 8/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9650F1 Macro Score: 0.7333985307173498\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1109 - accuracy: 0.9647 - val_loss: 0.4160 - val_accuracy: 0.9138\n",
      "Epoch 9/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.9655F1 Macro Score: 0.7680926636550184\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1074 - accuracy: 0.9653 - val_loss: 0.3410 - val_accuracy: 0.9281\n",
      "Epoch 10/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9651F1 Macro Score: 0.793867036193743\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1069 - accuracy: 0.9652 - val_loss: 0.2767 - val_accuracy: 0.9369\n",
      "Epoch 11/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9660F1 Macro Score: 0.8786278780942492\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1044 - accuracy: 0.9659 - val_loss: 0.2110 - val_accuracy: 0.9509\n",
      "Epoch 12/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9659F1 Macro Score: 0.8762543566756743\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1032 - accuracy: 0.9659 - val_loss: 0.1841 - val_accuracy: 0.9530\n",
      "Epoch 13/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.9666F1 Macro Score: 0.8874882126113743\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.1005 - accuracy: 0.9665 - val_loss: 0.1594 - val_accuracy: 0.9564\n",
      "Epoch 14/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9666F1 Macro Score: 0.9009728501761642\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0998 - accuracy: 0.9665 - val_loss: 0.1435 - val_accuracy: 0.9592\n",
      "Epoch 15/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9665F1 Macro Score: 0.9090113082327815\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0994 - accuracy: 0.9666 - val_loss: 0.1335 - val_accuracy: 0.9595\n",
      "Epoch 16/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9665F1 Macro Score: 0.8957491548952586\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0988 - accuracy: 0.9666 - val_loss: 0.1361 - val_accuracy: 0.9563\n",
      "Epoch 17/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9667F1 Macro Score: 0.9213539229742423\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0977 - accuracy: 0.9668 - val_loss: 0.1133 - val_accuracy: 0.9632\n",
      "Epoch 18/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9667F1 Macro Score: 0.9205834641712394\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0970 - accuracy: 0.9668 - val_loss: 0.1078 - val_accuracy: 0.9641\n",
      "Epoch 19/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9671F1 Macro Score: 0.9219141284020114\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0957 - accuracy: 0.9670 - val_loss: 0.1105 - val_accuracy: 0.9629\n",
      "Epoch 20/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9668F1 Macro Score: 0.9357564158914647\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0963 - accuracy: 0.9668 - val_loss: 0.0980 - val_accuracy: 0.9664\n",
      "Epoch 21/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9666F1 Macro Score: 0.9361464595627914\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0984 - accuracy: 0.9666 - val_loss: 0.0968 - val_accuracy: 0.9664\n",
      "Epoch 22/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9672F1 Macro Score: 0.935350860437887\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0963 - accuracy: 0.9669 - val_loss: 0.0990 - val_accuracy: 0.9659\n",
      "Epoch 23/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9666F1 Macro Score: 0.9330383240959744\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.0960 - accuracy: 0.9669 - val_loss: 0.0980 - val_accuracy: 0.9659\n",
      "Epoch 24/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9674F1 Macro Score: 0.9358130719753742\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0941 - accuracy: 0.9673 - val_loss: 0.0944 - val_accuracy: 0.9665\n",
      "Epoch 25/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9673F1 Macro Score: 0.9345524952914008\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0932 - accuracy: 0.9674 - val_loss: 0.0963 - val_accuracy: 0.9660\n",
      "Epoch 26/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9671F1 Macro Score: 0.9360513637183768\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0928 - accuracy: 0.9674 - val_loss: 0.0937 - val_accuracy: 0.9664\n",
      "Epoch 27/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9675F1 Macro Score: 0.9367529499456186\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0928 - accuracy: 0.9674 - val_loss: 0.0924 - val_accuracy: 0.9667\n",
      "Epoch 28/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9674F1 Macro Score: 0.9348746325032855\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0919 - accuracy: 0.9675 - val_loss: 0.0925 - val_accuracy: 0.9665\n",
      "Epoch 29/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9680F1 Macro Score: 0.9361066738023051\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0912 - accuracy: 0.9676 - val_loss: 0.0930 - val_accuracy: 0.9665\n",
      "Epoch 30/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9676F1 Macro Score: 0.9355623861264939\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0912 - accuracy: 0.9675 - val_loss: 0.0942 - val_accuracy: 0.9662\n",
      "Training fold 1 completed. macro f1 score : 0.9355623861264939\n",
      "Train on 1041 samples, validate on 209 samples\n",
      "Epoch 1/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.8329 - accuracy: 0.7052F1 Macro Score: 0.41150791191482755\n",
      "1041/1041 [==============================] - 60s 57ms/sample - loss: 0.8291 - accuracy: 0.7069 - val_loss: 1.2641 - val_accuracy: 0.6779\n",
      "Epoch 2/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.8596F1 Macro Score: 0.43648976926859984\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.3701 - accuracy: 0.8606 - val_loss: 1.1474 - val_accuracy: 0.7080\n",
      "Epoch 3/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9299F1 Macro Score: 0.5536210559331942\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.2033 - accuracy: 0.9307 - val_loss: 1.0068 - val_accuracy: 0.8049\n",
      "Epoch 4/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9531F1 Macro Score: 0.6029800840089756\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1470 - accuracy: 0.9533 - val_loss: 0.8165 - val_accuracy: 0.8313\n",
      "Epoch 5/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9595F1 Macro Score: 0.608971081814115\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1286 - accuracy: 0.9597 - val_loss: 0.6876 - val_accuracy: 0.8400\n",
      "Epoch 6/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9587F1 Macro Score: 0.5713324636882855\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1310 - accuracy: 0.9587 - val_loss: 0.6693 - val_accuracy: 0.8271\n",
      "Epoch 7/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9616F1 Macro Score: 0.7338337117598347\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1221 - accuracy: 0.9615 - val_loss: 0.4720 - val_accuracy: 0.8820\n",
      "Epoch 8/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9615F1 Macro Score: 0.8274515109007562\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1238 - accuracy: 0.9612 - val_loss: 0.3986 - val_accuracy: 0.9114\n",
      "Epoch 9/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9645F1 Macro Score: 0.8555089138407166\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.1121 - accuracy: 0.9643 - val_loss: 0.2917 - val_accuracy: 0.9343\n",
      "Epoch 10/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9645F1 Macro Score: 0.8465485421488363\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1090 - accuracy: 0.9646 - val_loss: 0.2535 - val_accuracy: 0.9377\n",
      "Epoch 11/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9654F1 Macro Score: 0.8914951002927929\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1060 - accuracy: 0.9653 - val_loss: 0.2038 - val_accuracy: 0.9478\n",
      "Epoch 12/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 0.9655F1 Macro Score: 0.8989223041354542\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1047 - accuracy: 0.9655 - val_loss: 0.1775 - val_accuracy: 0.9559\n",
      "Epoch 13/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9662F1 Macro Score: 0.924707979187867\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.1013 - accuracy: 0.9660 - val_loss: 0.1460 - val_accuracy: 0.9627\n",
      "Epoch 14/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9662F1 Macro Score: 0.9225280610299695\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.1004 - accuracy: 0.9661 - val_loss: 0.1317 - val_accuracy: 0.9632\n",
      "Epoch 15/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9663F1 Macro Score: 0.9257429566218067\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0995 - accuracy: 0.9664 - val_loss: 0.1219 - val_accuracy: 0.9641\n",
      "Epoch 16/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9663F1 Macro Score: 0.9267047549697005\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0986 - accuracy: 0.9664 - val_loss: 0.1191 - val_accuracy: 0.9634\n",
      "Epoch 17/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9662F1 Macro Score: 0.9274228692881749\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0990 - accuracy: 0.9663 - val_loss: 0.1073 - val_accuracy: 0.9653\n",
      "Epoch 18/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9661F1 Macro Score: 0.9322234865153461\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.0990 - accuracy: 0.9662 - val_loss: 0.1028 - val_accuracy: 0.9666\n",
      "Epoch 19/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9667F1 Macro Score: 0.93605530114382\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0968 - accuracy: 0.9667 - val_loss: 0.0974 - val_accuracy: 0.9675\n",
      "Epoch 20/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9665F1 Macro Score: 0.934483005306216\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0965 - accuracy: 0.9666 - val_loss: 0.0982 - val_accuracy: 0.9670\n",
      "Epoch 21/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9669F1 Macro Score: 0.9357458547080119\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0955 - accuracy: 0.9669 - val_loss: 0.0927 - val_accuracy: 0.9679\n",
      "Epoch 22/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9671F1 Macro Score: 0.9368678585570023\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0951 - accuracy: 0.9668 - val_loss: 0.0923 - val_accuracy: 0.9678\n",
      "Epoch 23/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9666F1 Macro Score: 0.9364456370755065\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0946 - accuracy: 0.9669 - val_loss: 0.0916 - val_accuracy: 0.9679\n",
      "Epoch 24/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9670F1 Macro Score: 0.9373731731589799\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0943 - accuracy: 0.9670 - val_loss: 0.0913 - val_accuracy: 0.9681\n",
      "Epoch 25/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9671F1 Macro Score: 0.9383906131122338\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0932 - accuracy: 0.9671 - val_loss: 0.0873 - val_accuracy: 0.9687\n",
      "Epoch 26/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9669F1 Macro Score: 0.9368112932552723\n",
      "1041/1041 [==============================] - 37s 36ms/sample - loss: 0.0928 - accuracy: 0.9672 - val_loss: 0.0917 - val_accuracy: 0.9678\n",
      "Epoch 27/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9672F1 Macro Score: 0.9376157329438282\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0931 - accuracy: 0.9671 - val_loss: 0.0876 - val_accuracy: 0.9685\n",
      "Epoch 28/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9669F1 Macro Score: 0.9369228804675963\n",
      "1041/1041 [==============================] - 36s 35ms/sample - loss: 0.0930 - accuracy: 0.9671 - val_loss: 0.0891 - val_accuracy: 0.9682\n",
      "Epoch 29/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 0.9675F1 Macro Score: 0.9363326063722738\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0921 - accuracy: 0.9672 - val_loss: 0.0894 - val_accuracy: 0.9680\n",
      "Epoch 30/30\n",
      "1024/1041 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 0.9673F1 Macro Score: 0.9381704094249366\n",
      "1041/1041 [==============================] - 37s 35ms/sample - loss: 0.0922 - accuracy: 0.9671 - val_loss: 0.0865 - val_accuracy: 0.9687\n",
      "Training fold 2 completed. macro f1 score : 0.9381704094249366\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.9479 - accuracy: 0.6977F1 Macro Score: 0.3473993703559642\n",
      "1042/1042 [==============================] - 60s 57ms/sample - loss: 0.9413 - accuracy: 0.6991 - val_loss: 1.4282 - val_accuracy: 0.5391\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.8616F1 Macro Score: 0.3317528119135107\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3634 - accuracy: 0.8623 - val_loss: 1.1843 - val_accuracy: 0.5524\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9318F1 Macro Score: 0.44387271657823885\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1993 - accuracy: 0.9322 - val_loss: 0.9846 - val_accuracy: 0.6204\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9535F1 Macro Score: 0.49732382080848636\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1490 - accuracy: 0.9538 - val_loss: 0.8864 - val_accuracy: 0.6763\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9609F1 Macro Score: 0.7306015658846744\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1288 - accuracy: 0.9608 - val_loss: 0.6954 - val_accuracy: 0.8543\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9625F1 Macro Score: 0.7609696845907155\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1212 - accuracy: 0.9627 - val_loss: 0.6362 - val_accuracy: 0.8233\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9641F1 Macro Score: 0.8278541061369871\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1174 - accuracy: 0.9634 - val_loss: 0.4994 - val_accuracy: 0.9027\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9648F1 Macro Score: 0.7966795190452114\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1241 - accuracy: 0.9611 - val_loss: 0.4779 - val_accuracy: 0.8921\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.9539F1 Macro Score: 0.8242524111175807\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1518 - accuracy: 0.9539 - val_loss: 0.4672 - val_accuracy: 0.8250\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9626F1 Macro Score: 0.909680528757427\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1235 - accuracy: 0.9629 - val_loss: 0.2878 - val_accuracy: 0.9487\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9648F1 Macro Score: 0.9196230239298242\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1124 - accuracy: 0.9650 - val_loss: 0.2404 - val_accuracy: 0.9544\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9653F1 Macro Score: 0.9232909682471454\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1083 - accuracy: 0.9655 - val_loss: 0.1915 - val_accuracy: 0.9611\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9658F1 Macro Score: 0.9290841004533651\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1054 - accuracy: 0.9659 - val_loss: 0.1547 - val_accuracy: 0.9642\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 0.9659F1 Macro Score: 0.9284691872370675\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1054 - accuracy: 0.9659 - val_loss: 0.1439 - val_accuracy: 0.9647\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9659F1 Macro Score: 0.9273258411730532\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1037 - accuracy: 0.9661 - val_loss: 0.1288 - val_accuracy: 0.9649\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9666F1 Macro Score: 0.9299157127447988\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1008 - accuracy: 0.9666 - val_loss: 0.1225 - val_accuracy: 0.9652\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9666F1 Macro Score: 0.9297951239952049\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0998 - accuracy: 0.9667 - val_loss: 0.1246 - val_accuracy: 0.9644\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9667F1 Macro Score: 0.9291671397707695\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1000 - accuracy: 0.9665 - val_loss: 0.1166 - val_accuracy: 0.9644\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9669F1 Macro Score: 0.9347343294915799\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0989 - accuracy: 0.9668 - val_loss: 0.1031 - val_accuracy: 0.9668\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9665F1 Macro Score: 0.9290214016950779\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0980 - accuracy: 0.9668 - val_loss: 0.1118 - val_accuracy: 0.9645\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9671F1 Macro Score: 0.9322471569476805\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0971 - accuracy: 0.9668 - val_loss: 0.1040 - val_accuracy: 0.9656\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9669F1 Macro Score: 0.9363260986201465\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0971 - accuracy: 0.9668 - val_loss: 0.0963 - val_accuracy: 0.9674\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9671F1 Macro Score: 0.9368127614276145\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0963 - accuracy: 0.9670 - val_loss: 0.0939 - val_accuracy: 0.9677\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9668F1 Macro Score: 0.9345795158988188\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0950 - accuracy: 0.9671 - val_loss: 0.0950 - val_accuracy: 0.9672\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9671F1 Macro Score: 0.9369478577035707\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0946 - accuracy: 0.9671 - val_loss: 0.0919 - val_accuracy: 0.9678\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9668F1 Macro Score: 0.9330613347668102\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0970 - accuracy: 0.9662 - val_loss: 0.1120 - val_accuracy: 0.9645\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9630F1 Macro Score: 0.9221177223389684\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1162 - accuracy: 0.9627 - val_loss: 0.1218 - val_accuracy: 0.9622\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9659F1 Macro Score: 0.9000056474668888\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1059 - accuracy: 0.9656 - val_loss: 0.1295 - val_accuracy: 0.9560\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9653F1 Macro Score: 0.9351669240537114\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1069 - accuracy: 0.9651 - val_loss: 0.0977 - val_accuracy: 0.9674\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9667F1 Macro Score: 0.9337849382954456\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0999 - accuracy: 0.9667 - val_loss: 0.1023 - val_accuracy: 0.9663\n",
      "Training fold 3 completed. macro f1 score : 0.9337849382954456\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.8884 - accuracy: 0.7051F1 Macro Score: 0.4100358669236655\n",
      "1042/1042 [==============================] - 61s 58ms/sample - loss: 0.8822 - accuracy: 0.7066 - val_loss: 1.3269 - val_accuracy: 0.6519\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8792F1 Macro Score: 0.4646174546900252\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3213 - accuracy: 0.8800 - val_loss: 1.3106 - val_accuracy: 0.7377\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.9403F1 Macro Score: 0.44113781021566933\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1808 - accuracy: 0.9406 - val_loss: 1.2001 - val_accuracy: 0.7266\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1430 - accuracy: 0.9558F1 Macro Score: 0.5596407988323634\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1423 - accuracy: 0.9561 - val_loss: 1.1033 - val_accuracy: 0.7682\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9621F1 Macro Score: 0.6350576615054738\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1237 - accuracy: 0.9620 - val_loss: 0.8436 - val_accuracy: 0.8481\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9635F1 Macro Score: 0.7087915416582647\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1162 - accuracy: 0.9637 - val_loss: 0.6971 - val_accuracy: 0.8854\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9646F1 Macro Score: 0.7463861172871872\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1146 - accuracy: 0.9640 - val_loss: 0.5378 - val_accuracy: 0.9048\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9658F1 Macro Score: 0.764139170201506\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1158 - accuracy: 0.9633 - val_loss: 0.5189 - val_accuracy: 0.9061\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.9619F1 Macro Score: 0.8464339975984352\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1245 - accuracy: 0.9619 - val_loss: 0.3149 - val_accuracy: 0.9313\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9650F1 Macro Score: 0.8474294878091094\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1097 - accuracy: 0.9653 - val_loss: 0.2624 - val_accuracy: 0.9330\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9660F1 Macro Score: 0.8701753956710355\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1036 - accuracy: 0.9661 - val_loss: 0.2230 - val_accuracy: 0.9410\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 0.9662F1 Macro Score: 0.8990755338710475\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1024 - accuracy: 0.9663 - val_loss: 0.1812 - val_accuracy: 0.9515\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9664F1 Macro Score: 0.9132889859671732\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1003 - accuracy: 0.9666 - val_loss: 0.1633 - val_accuracy: 0.9567\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9665F1 Macro Score: 0.9145576062788314\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0999 - accuracy: 0.9666 - val_loss: 0.1492 - val_accuracy: 0.9581\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9664F1 Macro Score: 0.9297656324591045\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0997 - accuracy: 0.9665 - val_loss: 0.1252 - val_accuracy: 0.9631\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9671F1 Macro Score: 0.9320450891078363\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0967 - accuracy: 0.9670 - val_loss: 0.1144 - val_accuracy: 0.9647\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9670F1 Macro Score: 0.9334046667269974\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0956 - accuracy: 0.9671 - val_loss: 0.1089 - val_accuracy: 0.9651\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9672F1 Macro Score: 0.9316168115683919\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0954 - accuracy: 0.9670 - val_loss: 0.1111 - val_accuracy: 0.9643\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.9672F1 Macro Score: 0.9313266642536319\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0950 - accuracy: 0.9671 - val_loss: 0.1067 - val_accuracy: 0.9643\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9668F1 Macro Score: 0.9337845288378491\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0947 - accuracy: 0.9671 - val_loss: 0.1005 - val_accuracy: 0.9659\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9674F1 Macro Score: 0.933850560191392\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0941 - accuracy: 0.9672 - val_loss: 0.0998 - val_accuracy: 0.9656\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9673F1 Macro Score: 0.9347372181938642\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0934 - accuracy: 0.9672 - val_loss: 0.0976 - val_accuracy: 0.9660\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9673F1 Macro Score: 0.9363427533220083\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0937 - accuracy: 0.9672 - val_loss: 0.0927 - val_accuracy: 0.9670\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9673F1 Macro Score: 0.9358592573891097\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0918 - accuracy: 0.9675 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9675F1 Macro Score: 0.9342537905565408\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0916 - accuracy: 0.9675 - val_loss: 0.0960 - val_accuracy: 0.9659\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9669F1 Macro Score: 0.9361665244121766\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0930 - accuracy: 0.9671 - val_loss: 0.0947 - val_accuracy: 0.9666\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9673F1 Macro Score: 0.9199549503651482\n",
      "1042/1042 [==============================] - 38s 36ms/sample - loss: 0.0949 - accuracy: 0.9670 - val_loss: 0.1031 - val_accuracy: 0.9642\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9673F1 Macro Score: 0.9342558880962986\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0940 - accuracy: 0.9670 - val_loss: 0.0941 - val_accuracy: 0.9665\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9669F1 Macro Score: 0.9358790386522952\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0950 - accuracy: 0.9666 - val_loss: 0.0925 - val_accuracy: 0.9667\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9673F1 Macro Score: 0.9367333664253212\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0924 - accuracy: 0.9674 - val_loss: 0.0907 - val_accuracy: 0.9672\n",
      "Training fold 4 completed. macro f1 score : 0.9367333664253212\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.8586 - accuracy: 0.7104F1 Macro Score: 0.4046152856026822\n",
      "1042/1042 [==============================] - 61s 59ms/sample - loss: 0.8519 - accuracy: 0.7122 - val_loss: 1.2710 - val_accuracy: 0.6087\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3047 - accuracy: 0.8857F1 Macro Score: 0.5437348058846814\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3032 - accuracy: 0.8863 - val_loss: 1.1570 - val_accuracy: 0.7758\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9453F1 Macro Score: 0.6138452567324347\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1654 - accuracy: 0.9456 - val_loss: 0.9835 - val_accuracy: 0.8262\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.9567F1 Macro Score: 0.6327805122874212\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1363 - accuracy: 0.9570 - val_loss: 0.8715 - val_accuracy: 0.8497\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9611F1 Macro Score: 0.6229881008282138\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1229 - accuracy: 0.9609 - val_loss: 0.7569 - val_accuracy: 0.8503\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.9618F1 Macro Score: 0.6544656050082299\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1191 - accuracy: 0.9619 - val_loss: 0.5922 - val_accuracy: 0.8696\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9634F1 Macro Score: 0.6805670401082865\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1181 - accuracy: 0.9625 - val_loss: 0.5060 - val_accuracy: 0.8798\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9641F1 Macro Score: 0.6737282675011251\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1226 - accuracy: 0.9605 - val_loss: 0.5209 - val_accuracy: 0.8732\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9553F1 Macro Score: 0.7629108025697502\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1462 - accuracy: 0.9553 - val_loss: 0.3412 - val_accuracy: 0.9035\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9631F1 Macro Score: 0.8310412206410667\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1179 - accuracy: 0.9633 - val_loss: 0.2447 - val_accuracy: 0.9408\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9648F1 Macro Score: 0.872293458162504\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1091 - accuracy: 0.9649 - val_loss: 0.2047 - val_accuracy: 0.9480\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9654F1 Macro Score: 0.8870882730072474\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1050 - accuracy: 0.9655 - val_loss: 0.1793 - val_accuracy: 0.9531\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9659F1 Macro Score: 0.9046813553725678\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1018 - accuracy: 0.9660 - val_loss: 0.1614 - val_accuracy: 0.9552\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1026 - accuracy: 0.9659F1 Macro Score: 0.9108523638452785\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1023 - accuracy: 0.9660 - val_loss: 0.1422 - val_accuracy: 0.9597\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9661F1 Macro Score: 0.9245834859155788\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1002 - accuracy: 0.9662 - val_loss: 0.1288 - val_accuracy: 0.9629\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9665F1 Macro Score: 0.9191403173071134\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0982 - accuracy: 0.9665 - val_loss: 0.1175 - val_accuracy: 0.9639\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9665F1 Macro Score: 0.9320889145353697\n",
      "1042/1042 [==============================] - 38s 36ms/sample - loss: 0.0976 - accuracy: 0.9665 - val_loss: 0.1111 - val_accuracy: 0.9654\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9666F1 Macro Score: 0.9312896072829967\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0976 - accuracy: 0.9665 - val_loss: 0.1075 - val_accuracy: 0.9657\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9669F1 Macro Score: 0.9334904621142331\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0961 - accuracy: 0.9668 - val_loss: 0.1052 - val_accuracy: 0.9657\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.9666F1 Macro Score: 0.9322642247938482\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0957 - accuracy: 0.9668 - val_loss: 0.1065 - val_accuracy: 0.9648\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9671F1 Macro Score: 0.936342562746665\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0947 - accuracy: 0.9669 - val_loss: 0.0967 - val_accuracy: 0.9671\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9670F1 Macro Score: 0.9362037198812818\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0948 - accuracy: 0.9669 - val_loss: 0.0953 - val_accuracy: 0.9670\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9671F1 Macro Score: 0.9380253958075823\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0943 - accuracy: 0.9670 - val_loss: 0.0901 - val_accuracy: 0.9681\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9668F1 Macro Score: 0.9382872679828966\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0934 - accuracy: 0.9671 - val_loss: 0.0908 - val_accuracy: 0.9679\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9671F1 Macro Score: 0.9370252651253487\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0934 - accuracy: 0.9671 - val_loss: 0.0903 - val_accuracy: 0.9678\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9666F1 Macro Score: 0.9373520869122498\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0945 - accuracy: 0.9669 - val_loss: 0.0945 - val_accuracy: 0.9672\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9670F1 Macro Score: 0.9306170669722792\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0966 - accuracy: 0.9668 - val_loss: 0.1023 - val_accuracy: 0.9650\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9671F1 Macro Score: 0.9378362214498868\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0949 - accuracy: 0.9668 - val_loss: 0.0896 - val_accuracy: 0.9679\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9664F1 Macro Score: 0.9369329715474174\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0969 - accuracy: 0.9661 - val_loss: 0.0910 - val_accuracy: 0.9676\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9664F1 Macro Score: 0.9379511808196187\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0974 - accuracy: 0.9664 - val_loss: 0.0913 - val_accuracy: 0.9678\n",
      "Training fold 5 completed. macro f1 score : 0.9379511808196187\n",
      "Train on 1042 samples, validate on 208 samples\n",
      "Epoch 1/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.8258 - accuracy: 0.7084F1 Macro Score: 0.385664021334722\n",
      "1042/1042 [==============================] - 63s 61ms/sample - loss: 0.8210 - accuracy: 0.7097 - val_loss: 1.3706 - val_accuracy: 0.5834\n",
      "Epoch 2/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.8764F1 Macro Score: 0.4534972593157988\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.3218 - accuracy: 0.8771 - val_loss: 1.2322 - val_accuracy: 0.6876\n",
      "Epoch 3/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.9399F1 Macro Score: 0.5664529345200688\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1772 - accuracy: 0.9402 - val_loss: 1.0884 - val_accuracy: 0.7611\n",
      "Epoch 4/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9570F1 Macro Score: 0.5347568835987919\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1356 - accuracy: 0.9572 - val_loss: 1.0411 - val_accuracy: 0.6779\n",
      "Epoch 5/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9621F1 Macro Score: 0.5578829620330994\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1195 - accuracy: 0.9620 - val_loss: 0.9190 - val_accuracy: 0.6698\n",
      "Epoch 6/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.9625F1 Macro Score: 0.5902186433997401\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1168 - accuracy: 0.9625 - val_loss: 0.8531 - val_accuracy: 0.6711\n",
      "Epoch 7/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.9639F1 Macro Score: 0.7186017568609122\n",
      "1042/1042 [==============================] - 38s 36ms/sample - loss: 0.1161 - accuracy: 0.9631 - val_loss: 0.5501 - val_accuracy: 0.8935\n",
      "Epoch 8/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9650F1 Macro Score: 0.6490162082361189\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1181 - accuracy: 0.9619 - val_loss: 0.7639 - val_accuracy: 0.6765\n",
      "Epoch 9/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9571F1 Macro Score: 0.7592120272578714\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1377 - accuracy: 0.9572 - val_loss: 0.5270 - val_accuracy: 0.8652\n",
      "Epoch 10/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9636F1 Macro Score: 0.7822048788769589\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1147 - accuracy: 0.9639 - val_loss: 0.4054 - val_accuracy: 0.8754\n",
      "Epoch 11/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9653F1 Macro Score: 0.8005667368260656\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1065 - accuracy: 0.9654 - val_loss: 0.3199 - val_accuracy: 0.9015\n",
      "Epoch 12/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9657F1 Macro Score: 0.8555651370897057\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.1035 - accuracy: 0.9659 - val_loss: 0.3293 - val_accuracy: 0.9063\n",
      "Epoch 13/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9662F1 Macro Score: 0.9100791746401835\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1007 - accuracy: 0.9663 - val_loss: 0.2229 - val_accuracy: 0.9494\n",
      "Epoch 14/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9662F1 Macro Score: 0.9081560363610727\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.1012 - accuracy: 0.9663 - val_loss: 0.1516 - val_accuracy: 0.9570\n",
      "Epoch 15/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9660F1 Macro Score: 0.9266081771564536\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.1009 - accuracy: 0.9662 - val_loss: 0.1305 - val_accuracy: 0.9620\n",
      "Epoch 16/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9667F1 Macro Score: 0.921822154361761\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0979 - accuracy: 0.9667 - val_loss: 0.1279 - val_accuracy: 0.9616\n",
      "Epoch 17/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9668F1 Macro Score: 0.9318681189468729\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0966 - accuracy: 0.9668 - val_loss: 0.1149 - val_accuracy: 0.9646\n",
      "Epoch 18/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9670F1 Macro Score: 0.9328052398189695\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.1105 - val_accuracy: 0.9657\n",
      "Epoch 19/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0955 - accuracy: 0.9669F1 Macro Score: 0.9326724067740503\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0958 - accuracy: 0.9669 - val_loss: 0.1066 - val_accuracy: 0.9653\n",
      "Epoch 20/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9668F1 Macro Score: 0.9334278663470208\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0944 - accuracy: 0.9671 - val_loss: 0.1031 - val_accuracy: 0.9656\n",
      "Epoch 21/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9672F1 Macro Score: 0.9355541170698358\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0939 - accuracy: 0.9670 - val_loss: 0.0961 - val_accuracy: 0.9671\n",
      "Epoch 22/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9674F1 Macro Score: 0.9383091615244599\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0929 - accuracy: 0.9672 - val_loss: 0.0895 - val_accuracy: 0.9681\n",
      "Epoch 23/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9669F1 Macro Score: 0.938446729269918\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0951 - accuracy: 0.9668 - val_loss: 0.0892 - val_accuracy: 0.9682\n",
      "Epoch 24/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9670F1 Macro Score: 0.9365854753907615\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0926 - accuracy: 0.9672 - val_loss: 0.0896 - val_accuracy: 0.9679\n",
      "Epoch 25/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9671F1 Macro Score: 0.9382930037854014\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0924 - accuracy: 0.9672 - val_loss: 0.0895 - val_accuracy: 0.9680\n",
      "Epoch 26/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9667F1 Macro Score: 0.9208998733261055\n",
      "1042/1042 [==============================] - 37s 36ms/sample - loss: 0.0940 - accuracy: 0.9668 - val_loss: 0.1155 - val_accuracy: 0.9616\n",
      "Epoch 27/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9667F1 Macro Score: 0.9365548299619338\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0984 - accuracy: 0.9664 - val_loss: 0.0936 - val_accuracy: 0.9674\n",
      "Epoch 28/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9675F1 Macro Score: 0.9373196969862218\n",
      "1042/1042 [==============================] - 36s 35ms/sample - loss: 0.0933 - accuracy: 0.9673 - val_loss: 0.0901 - val_accuracy: 0.9678\n",
      "Epoch 29/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9672F1 Macro Score: 0.9349203419323775\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0940 - accuracy: 0.9669 - val_loss: 0.0918 - val_accuracy: 0.9674\n",
      "Epoch 30/30\n",
      "1024/1042 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9670F1 Macro Score: 0.9383305504646742\n",
      "1042/1042 [==============================] - 37s 35ms/sample - loss: 0.0936 - accuracy: 0.9670 - val_loss: 0.0872 - val_accuracy: 0.9684\n",
      "Training fold 6 completed. macro f1 score : 0.9383305504646742\n",
      "Training completed. oof macro f1 score : 0.9367698069964363\n"
     ]
    }
   ],
   "source": [
    "for kalman, model_name in zip([True, False], ['kalman', 'non_kalman']):\n",
    "    train, test, sample_submission = read_data(kalman)\n",
    "    train, test = normalize(train, test)\n",
    "    train = run_feat_engineering(train, batch_size=GROUP_BATCH_SIZE)\n",
    "    test = run_feat_engineering(test, batch_size=GROUP_BATCH_SIZE)\n",
    "    train, test, features = feature_selection(train, test)\n",
    "\n",
    "    gc.collect()\n",
    "    run_cv_nn(train, test, SPLITS, features, EPOCHS, BATCHSIZE, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.588877,
     "end_time": "2021-01-12T11:15:24.451209",
     "exception": false,
     "start_time": "2021-01-12T11:15:21.862332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T11:15:29.323490Z",
     "iopub.status.busy": "2021-01-12T11:15:29.322478Z",
     "iopub.status.idle": "2021-01-12T11:15:36.035942Z",
     "shell.execute_reply": "2021-01-12T11:15:36.034685Z"
    },
    "papermill": {
     "duration": 8.995606,
     "end_time": "2021-01-12T11:15:36.036069",
     "exception": false,
     "start_time": "2021-01-12T11:15:27.040463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_npy = os.listdir('/kaggle/working/')\n",
    "pre_npy=[x for x in pre_npy if '.npy' in x]\n",
    "result = np.zeros((2000000, 11))\n",
    "# weights=[np.random.random() for _ in range(len(pre_npy))]\n",
    "weights = np.ones(len(pre_npy))\n",
    "\n",
    "weights /= np.sum(weights)\n",
    "for weight, pre_f in zip(weights, pre_npy):\n",
    "    result += np.load(\"/kaggle/working/%s\" % pre_f,) * weight\n",
    "\n",
    "sample_submission['open_channels'] = np.argmax(result, axis = 1).astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 13874.389015,
   "end_time": "2021-01-12T11:15:40.193860",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-12T07:24:25.804845",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
